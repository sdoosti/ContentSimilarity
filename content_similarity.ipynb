{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Content Similarity (Aug 14, 2024)\n",
    "\n",
    "In this file, I incorporate sponsor description and video description, labels, and transcripts.\n",
    "The similarity is calculated directly using the embedding vectors from google text embedding model with no topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data size: 38077\n",
      "Sponsored videos size: 34028\n",
      "Sponsors size: 4049\n",
      "Embeddings size: 38077\n"
     ]
    }
   ],
   "source": [
    "PATH = \"/home/doosti@chapman.edu/projects/Facebook/top2vec/data/\"\n",
    "# import data\n",
    "data = pd.read_csv(os.path.join(PATH, \"vca_combined_2024-08-13.csv\"))\n",
    "print(f\"Combined data size: {data.shape[0]}\")\n",
    "# sponsored videos\n",
    "sponsored = pd.read_csv(os.path.join(PATH, \"sponsored_videos_data.csv\"))\n",
    "print(f\"Sponsored videos size: {sponsored.shape[0]}\")\n",
    "# sponsors\n",
    "sponsors = pd.read_csv(os.path.join(PATH, \"sponsor_description.csv\"))\n",
    "print(f\"Sponsors size: {sponsors.shape[0]}\")\n",
    "with open(os.path.join(PATH, \"embeddings.pkl\"), \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "print(f\"Embeddings size: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsors['embeddings'] = embeddings[:sponsors.shape[0]]\n",
    "sponsored['embeddings'] = embeddings[sponsors.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id                  0\n",
      "new_id                    0\n",
      "creator_id                0\n",
      "creator_name              0\n",
      "sponsor_id             4414\n",
      "sponsor_name             11\n",
      "title_description         0\n",
      "topics                20567\n",
      "labels                24509\n",
      "labels2               24509\n",
      "transcript            27387\n",
      "text                      0\n",
      "embeddings                0\n",
      "sponsor_embeddings     3824\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find the sponsor embedding for each sponsored video\n",
    "sponsored['sponsor_embeddings'] = sponsored[['sponsor_name']].merge(sponsors, on='sponsor_name', how='left')['embeddings']\n",
    "print(sponsored.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find similar sponsors\n",
    "def find_similar_sponsors(sponsor_name, n=5):\n",
    "    sponsor_embedding = sponsors[sponsors['sponsor_name']==sponsor_name]['embeddings'].values[0]\n",
    "    cosine_sim = cosine_similarity([sponsor_embedding], sponsors['embeddings'].tolist())\n",
    "    similar_sponsors = sponsors.iloc[np.argsort(cosine_sim[0])[-n-1:-1]]['sponsor_name'].values\n",
    "    return list(zip(similar_sponsors[::-1], np.sort(cosine_sim[0])[-n-1:-1][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sponsor: Wisconsin Lottery\n",
      "Illinois Lottery               | 0.75\n",
      "Minnesota Lottery              | 0.73\n",
      "Georgia Lottery Corporation    | 0.73\n",
      "Quicken Loans Arena            | 0.70\n",
      "Yamaha Outdoors                | 0.68\n",
      "Adidas Hockey                  | 0.68\n",
      "ABC Television Network         | 0.68\n",
      "Warrior Lacrosse               | 0.67\n",
      "Tennessee Vacation             | 0.67\n",
      "Los Angeles Lakers             | 0.67\n"
     ]
    }
   ],
   "source": [
    "sponsor_sample = sponsors.sample(1)['sponsor_name'].values[0]\n",
    "print(f\"Sample sponsor: {sponsor_sample}\")\n",
    "for (sim_sponsor, score) in find_similar_sponsors(sponsor_sample, n=10):\n",
    "    # print the score with 2 decimal points\n",
    "    print(f\"{sim_sponsor:30s} | {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarity between a document and a creator\n",
    "def get_sponsorship_similarity(document_vector, creator_embedding):\n",
    "    if type(creator_embedding) != np.ndarray:\n",
    "        return np.nan\n",
    "    return cosine_similarity([document_vector], [creator_embedding])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34028/34028 [00:19<00:00, 1738.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    30204.000000\n",
      "mean         0.514502\n",
      "std          0.096106\n",
      "min          0.273755\n",
      "25%          0.439255\n",
      "50%          0.506337\n",
      "75%          0.579599\n",
      "max          0.941470\n",
      "Name: sponsorship_similarity, dtype: float64\n",
      "3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "sponsored['sponsorship_similarity'] = sponsored.progress_apply(lambda x: get_sponsorship_similarity(x['embeddings'], x['sponsor_embeddings']), axis=1).values\n",
    "\n",
    "print(sponsored.sponsorship_similarity.describe())\n",
    "print(sponsored.sponsorship_similarity.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'new_id', 'creator_id', 'creator_name', 'sponsor_id',\n",
       "       'sponsor_name', 'title_description', 'topics', 'labels', 'labels2',\n",
       "       'transcript', 'text', 'embeddings', 'sponsor_embeddings',\n",
       "       'sponsorship_similarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sponsored.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data\n",
    "sponsored[['video_id','new_id','creator_id','creator_name','sponsor_id','sponsor_name','sponsorship_similarity']].to_csv(os.path.join(PATH, \"sponsored_vca_aug2024.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemeni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
